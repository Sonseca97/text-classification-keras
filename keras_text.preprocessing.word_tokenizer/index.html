<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Word Tokenizer - Documentation Text Classification Keras</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  <link href="../css/extras.css" rel="stylesheet">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Word Tokenizer";
    var mkdocs_page_input_path = "keras_text.preprocessing.word_tokenizer.md";
    var mkdocs_page_url = "/keras_text.preprocessing.word_tokenizer/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Documentation Text Classification Keras</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">API Docs</span>
    <ul class="subnav">
                <li class="">
                    
    <span class="caption-text">Models</span>
    <ul class="subnav">
                <li class="toctree-l3">
                    
    <a class="" href="../keras_text.models.sequence_encoders/">Sequence Processing Models</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../keras_text.models.token_model/">Sequence Model Builder Factory</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../keras_text.models.sentence_model/">Sentence Model Builder Factory</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../keras_text.models.layers/">Custom Layers</a>
                </li>
    </ul>
                </li>
                <li class=" current">
                    
    <span class="caption-text">Preprocessing</span>
    <ul class="subnav">
                <li class="toctree-l3 current">
                    
    <a class="current" href="./">Word Tokenizer</a>
    <ul class="subnav">
            
    <li class="toctree-l4"><a href="#spacytokenizer">SpacyTokenizer</a></li>
    
        <ul>
        
            <li><a class="toctree-l5" href="#spacytokenizerhas_vocab">SpacyTokenizer.has_vocab</a></li>
        
            <li><a class="toctree-l5" href="#spacytokenizernum_texts">SpacyTokenizer.num_texts</a></li>
        
            <li><a class="toctree-l5" href="#spacytokenizernum_tokens">SpacyTokenizer.num_tokens</a></li>
        
            <li><a class="toctree-l5" href="#spacytokenizertoken_counts">SpacyTokenizer.token_counts</a></li>
        
            <li><a class="toctree-l5" href="#spacytokenizertoken_index">SpacyTokenizer.token_index</a></li>
        
            <li><a class="toctree-l5" href="#spacytokenizer__init__">SpacyTokenizer.__init__</a></li>
        
        </ul>
    

    <li class="toctree-l4"><a href="#twokenizetokenizer">TwokenizeTokenizer</a></li>
    
        <ul>
        
            <li><a class="toctree-l5" href="#twokenizetokenizerhas_vocab">TwokenizeTokenizer.has_vocab</a></li>
        
            <li><a class="toctree-l5" href="#twokenizetokenizernum_texts">TwokenizeTokenizer.num_texts</a></li>
        
            <li><a class="toctree-l5" href="#twokenizetokenizernum_tokens">TwokenizeTokenizer.num_tokens</a></li>
        
            <li><a class="toctree-l5" href="#twokenizetokenizertoken_counts">TwokenizeTokenizer.token_counts</a></li>
        
            <li><a class="toctree-l5" href="#twokenizetokenizertoken_index">TwokenizeTokenizer.token_index</a></li>
        
            <li><a class="toctree-l5" href="#twokenizetokenizer__init__">TwokenizeTokenizer.__init__</a></li>
        
        </ul>
    

    <li class="toctree-l4"><a href="#simpletokenizer">SimpleTokenizer</a></li>
    
        <ul>
        
            <li><a class="toctree-l5" href="#simpletokenizerhas_vocab">SimpleTokenizer.has_vocab</a></li>
        
            <li><a class="toctree-l5" href="#simpletokenizernum_texts">SimpleTokenizer.num_texts</a></li>
        
            <li><a class="toctree-l5" href="#simpletokenizernum_tokens">SimpleTokenizer.num_tokens</a></li>
        
            <li><a class="toctree-l5" href="#simpletokenizertoken_counts">SimpleTokenizer.token_counts</a></li>
        
            <li><a class="toctree-l5" href="#simpletokenizertoken_index">SimpleTokenizer.token_index</a></li>
        
            <li><a class="toctree-l5" href="#simpletokenizer__init__">SimpleTokenizer.__init__</a></li>
        
        </ul>
    

    <li class="toctree-l4"><a href="#fasttextwikitokenizer">FastTextWikiTokenizer</a></li>
    
        <ul>
        
            <li><a class="toctree-l5" href="#fasttextwikitokenizerhas_vocab">FastTextWikiTokenizer.has_vocab</a></li>
        
            <li><a class="toctree-l5" href="#fasttextwikitokenizernum_texts">FastTextWikiTokenizer.num_texts</a></li>
        
            <li><a class="toctree-l5" href="#fasttextwikitokenizernum_tokens">FastTextWikiTokenizer.num_tokens</a></li>
        
            <li><a class="toctree-l5" href="#fasttextwikitokenizertoken_counts">FastTextWikiTokenizer.token_counts</a></li>
        
            <li><a class="toctree-l5" href="#fasttextwikitokenizertoken_index">FastTextWikiTokenizer.token_index</a></li>
        
            <li><a class="toctree-l5" href="#fasttextwikitokenizer__init__">FastTextWikiTokenizer.__init__</a></li>
        
        </ul>
    

    </ul>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../keras_text.preprocessing.sentence_tokenizer/">Sentence Tokenizer</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../keras_text.preprocessing.tokenizer/">Tokenizer</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../keras_text.preprocessing.char_tokenizer/">Char Tokenizer</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../keras_text.preprocessing.utils/">Utils</a>
                </li>
    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../keras_text.embeddings/">Embeddings</a>
                </li>
                <li class="">
                    
    <a class="" href="../keras_text.experiment/">Experiment</a>
                </li>
                <li class="">
                    
    <a class="" href="../keras_text.corpus/">Corpus</a>
                </li>
                <li class="">
                    
    <a class="" href="../keras_text.data/">Data</a>
                </li>
                <li class="">
                    
    <span class="caption-text">Utils</span>
    <ul class="subnav">
                <li class="toctree-l3">
                    
    <a class="" href="../keras_text.utils.format/">Format</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../keras_text.utils.generators/">Generators</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../keras_text.utils.io/">IO</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../keras_text.utils.sampling/">Sampling</a>
                </li>
    </ul>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Documentation Text Classification Keras</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
        
          <li>API Docs &raquo;</li>
        
      
        
          <li>Preprocessing &raquo;</li>
        
      
    
    <li>Word Tokenizer</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="http://github.com/jfilter/text-classification-keras/blob/master/docs/templates/keras_text.preprocessing.word_tokenizer.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <p><strong>Source:</strong> <a href="https://github.com/jfilter/text-classification-keras/keras_text/preprocessing/word_tokenizer.py#L0">keras_text/preprocessing/word_tokenizer.py#L0</a></p>
<hr />
<h2 id="spacytokenizer"><a href="https://github.com/jfilter/text-classification-keras/keras_text/preprocessing/word_tokenizer.py#L8">SpacyTokenizer</a></h2>
<h4 id="spacytokenizerhas_vocab">SpacyTokenizer.has_vocab</h4>
<h4 id="spacytokenizernum_texts">SpacyTokenizer.num_texts</h4>
<p>The number of texts used to build the vocabulary.</p>
<h4 id="spacytokenizernum_tokens">SpacyTokenizer.num_tokens</h4>
<p>Number of unique tokens for use in enccoding/decoding.
This can change with calls to <code>apply_encoding_options</code>.</p>
<h4 id="spacytokenizertoken_counts">SpacyTokenizer.token_counts</h4>
<p>Dictionary of token -&gt; count values for the text corpus used to <code>build_vocab</code>.</p>
<h4 id="spacytokenizertoken_index">SpacyTokenizer.token_index</h4>
<p>Dictionary of token -&gt; idx mappings. This can change with calls to <code>apply_encoding_options</code>.</p>
<hr />
<h3 id="spacytokenizer__init__"><a href="https://github.com/jfilter/text-classification-keras/keras_text/preprocessing/word_tokenizer.py#L9">SpacyTokenizer.<code>__init__</code></a></h3>
<pre><code class="python">__init__(self, lang=&quot;en&quot;, lower=True, lemmatize=False, remove_punct=True, remove_digits=True, \
    remove_stop_words=False, exclude_oov=False, exclude_pos_tags=None, \
    exclude_entities=['PERSON'])
</code></pre>

<p>Encodes text into <code>(samples, words)</code></p>
<p><em>Args:</em></p>
<ul>
<li><strong>lang</strong>:  The spacy language to use. (Default value: 'en')</li>
<li><strong>lower</strong>:  Lower cases the tokens if True. (Default value: True)</li>
<li><strong>lemmatize</strong>:  Lemmatizes words when set to True. This also makes the word lower case
  irrespective if the <code>lower</code> setting. (Default value: False)</li>
<li><strong>remove_punct</strong>:  Removes punct words if True. (Default value: True)</li>
<li><strong>remove_digits</strong>:  Removes digit words if True. (Default value: True)</li>
<li><strong>remove_stop_words</strong>:  Removes stop words if True. (Default value: False)</li>
<li><strong>exclude_oov</strong>:  Exclude words that are out of spacy embedding's vocabulary.
  By default, GloVe 1 million, 300 dim are used. You can override spacy vocabulary with a custom
  embedding to change this. (Default value: False)</li>
<li><strong>exclude_pos_tags</strong>:  A list of parts of speech tags to exclude. Can be any of spacy.parts_of_speech.IDS
  (Default value: None)</li>
<li><strong>exclude_entities</strong>:  A list of entity types to be excluded.
  Supported entity types can be found here: https://spacy.io/docs/usage/entity-recognition#entity-types
  (Default value: ['PERSON'])</li>
</ul>
<hr />
<h2 id="twokenizetokenizer"><a href="https://github.com/jfilter/text-classification-keras/keras_text/preprocessing/word_tokenizer.py#L107">TwokenizeTokenizer</a></h2>
<h4 id="twokenizetokenizerhas_vocab">TwokenizeTokenizer.has_vocab</h4>
<h4 id="twokenizetokenizernum_texts">TwokenizeTokenizer.num_texts</h4>
<p>The number of texts used to build the vocabulary.</p>
<h4 id="twokenizetokenizernum_tokens">TwokenizeTokenizer.num_tokens</h4>
<p>Number of unique tokens for use in enccoding/decoding.
This can change with calls to <code>apply_encoding_options</code>.</p>
<h4 id="twokenizetokenizertoken_counts">TwokenizeTokenizer.token_counts</h4>
<p>Dictionary of token -&gt; count values for the text corpus used to <code>build_vocab</code>.</p>
<h4 id="twokenizetokenizertoken_index">TwokenizeTokenizer.token_index</h4>
<p>Dictionary of token -&gt; idx mappings. This can change with calls to <code>apply_encoding_options</code>.</p>
<hr />
<h3 id="twokenizetokenizer__init__"><a href="https://github.com/jfilter/text-classification-keras/keras_text/preprocessing/word_tokenizer.py#L108">TwokenizeTokenizer.<code>__init__</code></a></h3>
<pre><code class="python">__init__(self, lang=&quot;en&quot;, lower=True)
</code></pre>

<p>Encodes text into <code>(samples, aux_indices..., token)</code> where each token is mapped to a unique index starting
from <code>i</code>. <code>i</code> is the number of special tokens.</p>
<p><em>Args:</em></p>
<ul>
<li><strong>lang</strong>:  The spacy language to use. (Default value: 'en')</li>
<li><strong>lower</strong>:  Lower cases the tokens if True. (Default value: True)</li>
<li><strong>special_token</strong>:  The tokens that are reserved. Default: ['<UNK>', '<PAD>'], <UNK> for unknown words and <PAD> for padding token.</li>
</ul>
<hr />
<h2 id="simpletokenizer"><a href="https://github.com/jfilter/text-classification-keras/keras_text/preprocessing/word_tokenizer.py#L120">SimpleTokenizer</a></h2>
<h4 id="simpletokenizerhas_vocab">SimpleTokenizer.has_vocab</h4>
<h4 id="simpletokenizernum_texts">SimpleTokenizer.num_texts</h4>
<p>The number of texts used to build the vocabulary.</p>
<h4 id="simpletokenizernum_tokens">SimpleTokenizer.num_tokens</h4>
<p>Number of unique tokens for use in enccoding/decoding.
This can change with calls to <code>apply_encoding_options</code>.</p>
<h4 id="simpletokenizertoken_counts">SimpleTokenizer.token_counts</h4>
<p>Dictionary of token -&gt; count values for the text corpus used to <code>build_vocab</code>.</p>
<h4 id="simpletokenizertoken_index">SimpleTokenizer.token_index</h4>
<p>Dictionary of token -&gt; idx mappings. This can change with calls to <code>apply_encoding_options</code>.</p>
<hr />
<h3 id="simpletokenizer__init__"><a href="https://github.com/jfilter/text-classification-keras/keras_text/preprocessing/word_tokenizer.py#L121">SimpleTokenizer.<code>__init__</code></a></h3>
<pre><code class="python">__init__(self, lang=&quot;en&quot;, lower=True)
</code></pre>

<p>Encodes text into <code>(samples, aux_indices..., token)</code> where each token is mapped to a unique index starting
from <code>i</code>. <code>i</code> is the number of special tokens.</p>
<p><em>Args:</em></p>
<ul>
<li><strong>lang</strong>:  The spacy language to use. (Default value: 'en')</li>
<li><strong>lower</strong>:  Lower cases the tokens if True. (Default value: True)</li>
<li><strong>special_token</strong>:  The tokens that are reserved. Default: ['<UNK>', '<PAD>'], <UNK> for unknown words and <PAD> for padding token.</li>
</ul>
<hr />
<h2 id="fasttextwikitokenizer"><a href="https://github.com/jfilter/text-classification-keras/keras_text/preprocessing/word_tokenizer.py#L133">FastTextWikiTokenizer</a></h2>
<h4 id="fasttextwikitokenizerhas_vocab">FastTextWikiTokenizer.has_vocab</h4>
<h4 id="fasttextwikitokenizernum_texts">FastTextWikiTokenizer.num_texts</h4>
<p>The number of texts used to build the vocabulary.</p>
<h4 id="fasttextwikitokenizernum_tokens">FastTextWikiTokenizer.num_tokens</h4>
<p>Number of unique tokens for use in enccoding/decoding.
This can change with calls to <code>apply_encoding_options</code>.</p>
<h4 id="fasttextwikitokenizertoken_counts">FastTextWikiTokenizer.token_counts</h4>
<p>Dictionary of token -&gt; count values for the text corpus used to <code>build_vocab</code>.</p>
<h4 id="fasttextwikitokenizertoken_index">FastTextWikiTokenizer.token_index</h4>
<p>Dictionary of token -&gt; idx mappings. This can change with calls to <code>apply_encoding_options</code>.</p>
<hr />
<h3 id="fasttextwikitokenizer__init__"><a href="https://github.com/jfilter/text-classification-keras/keras_text/preprocessing/word_tokenizer.py#L134">FastTextWikiTokenizer.<code>__init__</code></a></h3>
<pre><code class="python">__init__(self, lang=&quot;en&quot;)
</code></pre>

<p>Encodes text into <code>(samples, aux_indices..., token)</code> where each token is mapped to a unique index starting
from <code>i</code>. <code>i</code> is the number of special tokens.</p>
<p><em>Args:</em></p>
<ul>
<li><strong>lang</strong>:  The spacy language to use. (Default value: 'en')</li>
<li><strong>lower</strong>:  Lower cases the tokens if True. (Default value: True)</li>
<li><strong>special_token</strong>:  The tokens that are reserved. Default: ['<UNK>', '<PAD>'], <UNK> for unknown words and <PAD> for padding token.</li>
</ul>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../keras_text.preprocessing.sentence_tokenizer/" class="btn btn-neutral float-right" title="Sentence Tokenizer">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../keras_text.models.layers/" class="btn btn-neutral" title="Custom Layers"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="http://github.com/jfilter/text-classification-keras/" class="fa fa-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../keras_text.models.layers/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../keras_text.preprocessing.sentence_tokenizer/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js"></script>
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script src="../search/require.js"></script>
      <script src="../search/search.js"></script>

</body>
</html>
